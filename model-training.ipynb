{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # Linear algebra\n",
    "import pandas as pd # Tabular data\n",
    "import matplotlib.pyplot as plt # Data visualization\n",
    "import seaborn as sns # High-level data visualization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # Object containing data\n",
    "from tensorflow.keras import Sequential # Model containing layers\n",
    "from tensorflow.keras import Input # Input layer\n",
    "from tensorflow.keras.layers import * # All other layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint # Executed after each epoch\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy # Loss for categorical data\n",
    "from tensorflow.keras.applications import * # Importing all model architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List containing disease names\n",
    "list_of_classes = ['Black Rot', 'ESCA', 'Leaf Blight', 'Healthy']\n",
    "# Variable containing batch size\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datagen that will be used for model training\n",
    "train_datagen = ImageDataGenerator().flow_from_directory('/kaggle/input/augmented-grape-disease-detection-dataset/Final Training Data',\n",
    "                                                         target_size = (224,224),\n",
    "                                                         batch_size = batch_size,\n",
    "                                                         class_mode = 'sparse',\n",
    "                                                         classes = list_of_classes,\n",
    "                                                         shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datagen that will be used for model validation\n",
    "validation_datagen = ImageDataGenerator().flow_from_directory('/kaggle/input/grape-disease-dataset-original/Original Data/test',\n",
    "                                                              target_size = (224,224),\n",
    "                                                              batch_size = batch_size,\n",
    "                                                              class_mode = 'sparse',\n",
    "                                                              classes = list_of_classes,\n",
    "                                                              shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datagen that will be used for model testing\n",
    "test_datagen = ImageDataGenerator().flow_from_directory('/kaggle/input/grape-disease-dataset-original/Original Data/test',\n",
    "                                                        target_size = (224,224),\n",
    "                                                        batch_size = batch_size,\n",
    "                                                        class_mode = 'sparse',\n",
    "                                                        classes = list_of_classes,\n",
    "                                                        shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model):\n",
    "    # Freezing the parameters of the pre-trained model \n",
    "    model.trainable = False\n",
    "    # Creating the final model\n",
    "    final_model = Sequential()\n",
    "    # Adding the pre-trained model\n",
    "    final_model.add(DenseNet121)\n",
    "    # Adding the GlobalAvgPool2D layer\n",
    "    final_model.add(GlobalAvgPool2D())\n",
    "    # Adding a Dense layer with 4 neurons and softmax activation\n",
    "    final_model.add(Dense(4, activation='softmax'))\n",
    "    # Printing the summary of the model\n",
    "    final_model.summary()\n",
    "    # Returning the final model\n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training History Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(model_name, model_history):\n",
    "    ### Training accuracy:\n",
    "    # Setting figsize and dpi for the plot\n",
    "    plt.figure(figsize=(2,1.5), dpi=96)\n",
    "    # Plotting accuracy\n",
    "    plt.plot(model_history.history['accuracy'])\n",
    "    # Plotting validation accuracy\n",
    "    plt.plot(model_history.history['val_accuracy'])\n",
    "    # Adding the title\n",
    "    plt.title(f'{model_name} Accuracy')\n",
    "    # Adding x and y labels\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    # Adding the legend\n",
    "    plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "    # Displaying the plot\n",
    "    plt.show()\n",
    "\n",
    "    ### Training loss:\n",
    "    # Setting figsize and dpi for the plot\n",
    "    plt.figure(figsize=(2.2,1.65), dpi=96)\n",
    "    # Plotting loss\n",
    "    plt.plot(model_history.history['loss'])\n",
    "    # Plotting validation loss\n",
    "    plt.plot(model_history.history['val_loss'])\n",
    "    # Adding the title\n",
    "    plt.title(f'{model_name} Loss')\n",
    "    # Adding x and y labels\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    # Adding the legend\n",
    "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "    # Displaying the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the baseline CNN model\n",
    "baseline_CNN_model = Sequential([Input(shape=(224,224,3)),\n",
    "                                 Conv2D(32, 6, padding='same', activation='relu'),\n",
    "                                 BatchNormalization(),\n",
    "                                 MaxPooling2D(),\n",
    "                                 Conv2D(32, 5, padding='same', activation='relu'),\n",
    "                                 BatchNormalization(),\n",
    "                                 MaxPooling2D(),\n",
    "                                 Conv2D(32, 4, padding='same', activation='relu'),\n",
    "                                 BatchNormalization(),\n",
    "                                 MaxPooling2D(),\n",
    "                                 Conv2D(32, 3, padding='same', activation='relu'),\n",
    "                                 BatchNormalization(),\n",
    "                                 MaxPooling2D(),\n",
    "                                 Conv2D(32, 3, padding='same', activation='relu'),\n",
    "                                 BatchNormalization(),\n",
    "                                 MaxPooling2D(),\n",
    "                                 Conv2D(32, 3, padding='same', activation='relu'),\n",
    "                                 BatchNormalization(),\n",
    "                                 Conv2D(32, 3, padding='same', activation='relu'),\n",
    "                                 BatchNormalization(),\n",
    "                                 MaxPooling2D(),\n",
    "                                 Dropout(0.2),\n",
    "                                 Flatten(),\n",
    "                                 Dense(512, activation='relu'),\n",
    "                                 Dense(512, activation='relu'),\n",
    "                                 Dense(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the summary of the model\n",
    "baseline_CNN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing EarlyStopping with val_loss and ModelCheckpoint with val_accuracy\n",
    "baseline_CNN_callbacks = [EarlyStopping(monitor='val_loss', patience=8, mode='min', restore_best_weights=True),\n",
    "                          ModelCheckpoint('/kaggle/working/model_weights/baseline_CNN_weights.hdf5',save_best_only=True,monitor='val_accuracy',mode='max')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model using Adam optimizer and sparse categorical crossentropy loss\n",
    "baseline_CNN_model.compile(optimizer = 'adam',\n",
    "                           loss = SparseCategoricalCrossentropy(from_logits=True),\n",
    "                           metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model for 25 epochs and saving the history\n",
    "final_baseline_CNN_model_history = baseline_CNN_model.fit(train_datagen,\n",
    "                                                          callbacks = baseline_CNN_callbacks,\n",
    "                                                          batch_size = batch_size,\n",
    "                                                          validation_data = validation_datagen,\n",
    "                                                          epochs = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting pre-trained weights\n",
    "DenseNet121 = DenseNet121(input_shape=(224,224,3), include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the final model\n",
    "final_DenseNet121_model = build_model(DenseNet121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing EarlyStopping with val_loss and ModelCheckpoint with val_accuracy\n",
    "DenseNet121_callbacks = [EarlyStopping(monitor='val_loss', patience=8, mode='min', restore_best_weights=True),\n",
    "                         ModelCheckpoint('/kaggle/working/model_weights/DenseNet121_weights.hdf5',save_best_only=True,monitor='val_accuracy',mode='max')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model using Adam optimizer and sparse categorical crossentropy loss\n",
    "final_DenseNet121_model.compile(optimizer = 'adam',\n",
    "                                loss = 'sparse_categorical_crossentropy',\n",
    "                                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model for 25 epochs and saving the history\n",
    "final_DenseNet121_model_history = final_DenseNet121_model.fit(train_datagen,\n",
    "                                                              callbacks = DenseNet121_callbacks,\n",
    "                                                              batch_size = batch_size,\n",
    "                                                              validation_data = validation_datagen,\n",
    "                                                              epochs = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNetB7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting pre-trained weights\n",
    "EfficientNetB7 = EfficientNetB7(input_shape=(224,224,3), include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the final model\n",
    "final_EfficientNetB7_model = build_model(EfficientNetB7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing EarlyStopping with val_loss and ModelCheckpoint with val_accuracy\n",
    "EfficientNetB7_callbacks = [EarlyStopping(monitor='val_loss', patience=8, mode='min', restore_best_weights=True),\n",
    "                            ModelCheckpoint('/kaggle/working/model_weights/EfficientNetB7_weights.hdf5',save_best_only=True,monitor='val_accuracy',mode='max')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model using Adam optimizer and sparse categorical crossentropy loss\n",
    "final_EfficientNetB7_model.compile(optimizer = 'adam',\n",
    "                                   loss = 'sparse_categorical_crossentropy', \n",
    "                                   metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model for 25 epochs and saving the history\n",
    "final_EfficientNetB7_model_history = final_EfficientNetB7_model.fit(train_datagen,\n",
    "                                                                    callbacks = EfficientNetB7_callbacks,\n",
    "                                                                    batch_size = batch_size, \n",
    "                                                                    validation_data = validation_datagen,\n",
    "                                                                    epochs = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting pre-trained weights\n",
    "MobileNetV2 = MobileNetV2(input_shape=(224,224,3), include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the final model\n",
    "final_MobileNetV2_model = build_model(MobileNetV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing EarlyStopping with val_loss and ModelCheckpoint with val_accuracy\n",
    "MobileNetV2_callbacks = [EarlyStopping(monitor='val_loss', patience=8, mode='min', restore_best_weights=True),\n",
    "                         ModelCheckpoint('/kaggle/working/model_weights/MobileNetV2_weights.hdf5',save_best_only=True,monitor='val_accuracy',mode='max')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model using Adam optimizer and sparse categorical crossentropy loss\n",
    "final_MobileNetV2_model.compile(optimizer = 'adam',\n",
    "                                loss = 'sparse_categorical_crossentropy',\n",
    "                                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model for 25 epochs and saving the history\n",
    "final_MobileNetV2_model_history = final_MobileNetV2_model.fit(train_datagen,\n",
    "                                                              callbacks = MobileNetV2_callbacks,\n",
    "                                                              batch_size = batch_size,\n",
    "                                                              validation_data = validation_datagen,\n",
    "                                                              epochs = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting pre-trained weights\n",
    "ResNet50 = ResNet50(input_shape=(224,224,3), include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the final model\n",
    "final_ResNet50_model = build_model(ResNet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing EarlyStopping with val_loss and ModelCheckpoint with val_accuracy\n",
    "ResNet50_callbacks = [EarlyStopping(monitor='val_loss', patience=8, mode='min', restore_best_weights=True),\n",
    "                      ModelCheckpoint('/kaggle/working/model_weights/ResNet50_weights.hdf5',save_best_only=True,monitor='val_accuracy',mode='max')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model using Adam optimizer and sparse categorical crossentropy loss\n",
    "final_ResNet50_model.compile(optimizer = 'adam',\n",
    "                             loss = 'sparse_categorical_crossentropy',\n",
    "                             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model for 25 epochs and saving the history\n",
    "final_ResNet50_model_history = final_ResNet50_model.fit(train_datagen,\n",
    "                                                        callbacks = ResNet50_callbacks,\n",
    "                                                        batch_size = batch_size,\n",
    "                                                        validation_data = validation_datagen,\n",
    "                                                        epochs = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting pre-trained weights\n",
    "VGG16 = VGG16(input_shape=(224,224,3), include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the final model\n",
    "final_VGG16_model = build_model(VGG16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing EarlyStopping with val_loss and ModelCheckpoint with val_accuracy\n",
    "VGG16_callbacks = [EarlyStopping(monitor='val_loss', patience=8, mode='min', restore_best_weights=True),\n",
    "                   ModelCheckpoint('/kaggle/working/model_weights/VGG16_weights.hdf5',save_best_only=True,monitor='val_accuracy',mode='max')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model using Adam optimizer and sparse categorical crossentropy loss\n",
    "final_VGG16_model.compile(optimizer = 'adam',\n",
    "                          loss = 'sparse_categorical_crossentropy', \n",
    "                          metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model for 25 epochs and saving the history\n",
    "final_VGG16_model_history = final_VGG16_model.fit(train_datagen,\n",
    "                                                  callbacks = VGG16_callbacks,\n",
    "                                                  batch_size = batch_size,\n",
    "                                                  validation_data = validation_datagen,\n",
    "                                                  epochs = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the plot_training_history function\n",
    "plot_training_history(model_name='Baseline CNN', model_history=final_baseline_CNN_model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the plot_training_history function\n",
    "plot_training_history(model_name='DenseNet121', model_history=final_DenseNet121_model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the plot_training_history function\n",
    "plot_training_history(model_name='EfficientNetB7', model_history=final_EfficientNetB7_model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the plot_training_history function\n",
    "plot_training_history(model_name='MobileNetV2', model_history=final_MobileNetV2_model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the plot_training_history function\n",
    "plot_training_history(model_name='ResNet50', model_history=final_ResNet50_model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the plot_training_history function\n",
    "plot_training_history(model_name='VGG16', model_history=final_VGG16_model_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
