{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # Linear algebra\n",
    "import pandas as pd # Tabular data\n",
    "import matplotlib.pyplot as plt # Data visualization\n",
    "import seaborn as sns # High-level data visualization\n",
    "import PIL # Image manipulation\n",
    "import time # Timing\n",
    "from tensorflow.keras.models import load_model # Loading model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # Object containing data\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report # Model metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Model Weights and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using tensorflow to load pretrained model weights\n",
    "baseline_CNN_model = load_model(\"/kaggle/input/grapevine-disease-detection-model-weights/model_weights/baseline_CNN_weights.hdf5\")\n",
    "DenseNet121_model = load_model(\"/kaggle/input/grapevine-disease-detection-model-weights/model_weights/DenseNet121_weights.hdf5\")\n",
    "EfficientNetB7_model = load_model(\"/kaggle/input/grapevine-disease-detection-model-weights/model_weights/EfficientNetB7_weights.hdf5\")\n",
    "MobileNetV2_model = load_model(\"/kaggle/input/grapevine-disease-detection-model-weights/model_weights/MobileNetV2_weights.hdf5\")\n",
    "ResNet50_model = load_model(\"/kaggle/input/grapevine-disease-detection-model-weights/model_weights/ResNet50_weights.hdf5\")\n",
    "VGG16_model = load_model(\"/kaggle/input/grapevine-disease-detection-model-weights/model_weights/VGG16_weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List containing disease names\n",
    "list_of_classes = ['Black Rot', 'ESCA', 'Leaf Blight', 'Healthy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datagen that will be used for model predictions and efficiency test\n",
    "test_datagen = ImageDataGenerator().flow_from_directory('/kaggle/input/grape-disease-dataset-original/Original Data/test',\n",
    "                                                        target_size = (224,224),\n",
    "                                                        batch_size = 32,\n",
    "                                                        class_mode = 'sparse',\n",
    "                                                        classes = list_of_classes,\n",
    "                                                        shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to make test images (batch_size is equal to total number of test images)\n",
    "plotting_datagen = ImageDataGenerator().flow_from_directory('/kaggle/input/grape-disease-dataset-original/Original Data/test',\n",
    "                                                            target_size = (224,224),\n",
    "                                                            batch_size = 1805,\n",
    "                                                            class_mode = 'sparse',\n",
    "                                                            classes = list_of_classes,\n",
    "                                                            shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object containing all testing images that is used for error visualization\n",
    "test_images = plotting_datagen[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, model_name, model_predictions=None, error_rows=4, error_cols=4):\n",
    "    ### Accuracy score:\n",
    "    try:\n",
    "        # Checking if model_predictions is None\n",
    "        model_predictions[0]\n",
    "    except:\n",
    "        # Getting model_predictions from the model and test_datagen\n",
    "        model_predictions = model.predict(test_datagen, verbose=0) \n",
    "        # Converting probabilistic predictions to integers\n",
    "        final_model_predictions = np.argmax(model_predictions, axis=-1)\n",
    "    else:\n",
    "        # Execute when model_predictions has been given\n",
    "        final_model_predictions = model_predictions \n",
    "    # Calculating model_accuracy using accuracy_score function from sklearn.metrics\n",
    "    model_accuracy = round(accuracy_score(final_model_predictions, test_datagen.labels)*100, 3)\n",
    "    # Printing model_name and model_accuracy\n",
    "    print(f'The {model_name} had an accuracy of {model_accuracy}%.', end='\\n\\n')\n",
    "    \n",
    "    ### Confusion matrix\n",
    "    # Getting model_confusion_matrix using confusion_matrix function from sklearn.metrics\n",
    "    model_confusion_matrix = confusion_matrix(y_true=test_datagen.labels,y_pred=final_model_predictions)\n",
    "    # Setting figsize and dpi for the plot\n",
    "    plt.figure(figsize=(2,2), dpi=96)\n",
    "    # Adding the title\n",
    "    plt.title(f'{model_name}')\n",
    "    # Rotating xticks\n",
    "    plt.xticks(rotation=0)\n",
    "    # Plotting heatmap\n",
    "    sns.heatmap(model_confusion_matrix, vmin=0, vmax=500, annot=True, fmt='d',\n",
    "                xticklabels=list_of_classes, yticklabels=list_of_classes, cbar=False)\n",
    "    # Adding x and y labels\n",
    "    plt.xlabel('Predicted Disease')\n",
    "    plt.ylabel('Actual Disease')\n",
    "    # Displaying plot\n",
    "    plt.show()\n",
    "    \n",
    "    ### Classification report\n",
    "    print(classification_report(y_true=test_datagen.labels,y_pred=final_model_predictions))\n",
    "    \n",
    "    ### Error visualization\n",
    "    # Getting indices of model errors\n",
    "    model_errors = (final_model_predictions - test_datagen.labels != 0)\n",
    "    # Getting the corresponding images\n",
    "    model_image_errors = test_images[model_errors]\n",
    "    # Getting the predicted labels\n",
    "    model_pred_errors = np.array(final_model_predictions)[model_errors]\n",
    "    # Getting the true labels\n",
    "    model_actual_errors = test_datagen.labels[model_errors]\n",
    "    # Function that adds a frame around the image\n",
    "    def frame_image(image, frame_width):\n",
    "        # Getting image dimensions in pixels\n",
    "        y_pixels, x_pixels = image.shape[0], image.shape[1]\n",
    "        # Creating an black RGB image with dimensions frame_width*2 + y_pixels and frame_width*2 + x_pixels\n",
    "        empty_image = PIL.Image.new('RGB', (frame_width*2+y_pixels,frame_width*2+x_pixels), (0,0,0))\n",
    "        # Converting the empty image to a numpy array\n",
    "        framed_image = np.array(empty_image.getdata()).reshape(empty_image.size[0], empty_image.size[1], 3)\n",
    "        # Adding the original image inside the frame\n",
    "        framed_image[frame_width:-frame_width, frame_width:-frame_width] = image\n",
    "        # Returning the framed image\n",
    "        return framed_image\n",
    "    # Error index\n",
    "    n = 0\n",
    "    # Subplots\n",
    "    fig, ax = plt.subplots(error_rows,error_cols,figsize=(7.5,2.25*error_rows), dpi=96)\n",
    "    # Iterating over rows\n",
    "    for row in range(error_rows):\n",
    "        # Iterating over columns\n",
    "        for col in range(error_cols):\n",
    "            try:\n",
    "                # Check if there are multiple error_rows\n",
    "                if error_rows > 1:\n",
    "                    # Add the title\n",
    "                    ax[row,col].set_title(f'Predicted label: {model_pred_errors[n]}\\nTrue label: {model_actual_errors[n]}')\n",
    "                    # Plot the image\n",
    "                    ax[row,col].imshow(frame_image(model_image_errors[n],5))\n",
    "                    # Set the aspect ratio\n",
    "                    ax[row,col].set_aspect(aspect=1)\n",
    "                else:\n",
    "                    # Add the title\n",
    "                    ax[col].set_title(f'Predicted label: {model_pred_errors[n]}\\nTrue label: {model_actual_errors[n]}')\n",
    "                    # Plot the image\n",
    "                    ax[col].imshow(frame_image(model_image_errors[n],5))\n",
    "                    # Set the aspect ratio\n",
    "                    ax[col].set_aspect(aspect=1)\n",
    "                # Increment the error index\n",
    "                n += 1\n",
    "            except:\n",
    "                # Do nothing\n",
    "                pass\n",
    "            # Check if there are multiple error_rows\n",
    "            if error_rows > 1:\n",
    "                # Remove axis\n",
    "                ax[row,col].axis('off')\n",
    "            else:\n",
    "                # Remove axis\n",
    "                ax[col].axis('off')\n",
    "    # Display the subplots\n",
    "    plt.show()\n",
    "    # Return the model predictions and model accuracy\n",
    "    return final_model_predictions, model_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parameters\n",
    "plt.rc('xtick', labelsize=6)\n",
    "plt.rc('ytick', labelsize=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the evaluate_model function\n",
    "baseline_CNN_preds, baseline_CNN_acc = evaluate_model(model = baseline_CNN_model,\n",
    "                                                      model_name = 'Baseline CNN',\n",
    "                                                      error_rows = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the evaluate_model function\n",
    "DenseNet121_preds, DenseNet121_acc = evaluate_model(model = DenseNet121_model,\n",
    "                                                    model_name = 'DenseNet121',\n",
    "                                                    error_rows = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the evaluate_model function\n",
    "EfficientNetB7_preds, EfficientNetB7_acc = evaluate_model(model = EfficientNetB7_model,\n",
    "                                                          model_name = 'EfficientNetB7',\n",
    "                                                          error_rows = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the evaluate_model function\n",
    "MobileNetV2_preds, MobileNetV2_acc = evaluate_model(model = MobileNetV2_model,\n",
    "                                                    model_name = 'MobileNetV2',\n",
    "                                                    error_rows = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the evaluate_model function\n",
    "ResNet50_preds, ResNet50_acc = evaluate_model(model = ResNet50_model,\n",
    "                                              model_name = 'ResNet50',\n",
    "                                              error_rows = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the evaluate_model function\n",
    "VGG16_preds, VGG16_acc = evaluate_model(model = VGG16_model,\n",
    "                                        model_name = 'VGG16',\n",
    "                                        error_rows = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary containing accuracies of the models\n",
    "accuracies = {'Model':['Baseline CNN', 'DenseNet121', 'EfficientNetB7', 'MobileNetV2', 'ResNet50', 'VGG16'],\n",
    "              'Accuracy':[baseline_CNN_acc, DenseNet121_acc, EfficientNetB7_acc, MobileNetV2_acc, ResNet50_acc, VGG16_acc]}\n",
    "# Converting dictionary to a dataframe\n",
    "accuracies = pd.DataFrame(accuracies)\n",
    "# Sorting by accuracy\n",
    "accuracies = accuracies.sort_values('Accuracy',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parameters\n",
    "plt.rc('xtick', labelsize=8)\n",
    "plt.rc('ytick', labelsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting figsize and dpi for the plot\n",
    "plt.figure(figsize=(7,5), dpi=100)\n",
    "# Adding the title\n",
    "plt.title('Accuracies of Different Models')\n",
    "# Rotating xticks\n",
    "plt.xticks(rotation=0)\n",
    "# Setting y limits\n",
    "plt.ylim([90,100])\n",
    "# Plotting barplot\n",
    "sns.barplot(data=accuracies, x='Model', y='Accuracy', palette='inferno')\n",
    "# Displaying plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary containing model sizes of the models\n",
    "model_sizes = {'Model Size (MB)':[28.91, 257.8, 9.4, 94.78, 58.94],\n",
    "               'Accuracy':[DenseNet121_acc, EfficientNetB7_acc, MobileNetV2_acc, ResNet50_acc, VGG16_acc]}\n",
    "# Converting dictionary to a dataframe\n",
    "model_sizes = pd.DataFrame(model_sizes)\n",
    "# Sorting by model sizes\n",
    "model_sizes = model_sizes.sort_values('Model Size (MB)',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset plot parameters\n",
    "plt.rcdefaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting figsize and dpi for the plot\n",
    "plt.figure(figsize=(7,5), dpi=100)\n",
    "# Adding the title\n",
    "plt.title('Model Size vs Accuracy')\n",
    "# Rotating xticks\n",
    "plt.xticks(rotation=0)\n",
    "# Setting y limits\n",
    "plt.ylim([90,100])\n",
    "# Plotting regplot\n",
    "sns.regplot(data=model_sizes, x='Model Size (MB)', y='Accuracy', color='b', lowess=True)\n",
    "# Displaying plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max-Voting Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_voting_ensemble(pred1,pred2,pred3):\n",
    "    # Will contain final predictions\n",
    "    final_pred = []\n",
    "    # Iterating over length of testing data\n",
    "    for i in range(1805):\n",
    "        # Will contain prediction counts\n",
    "        pred_counts = []\n",
    "        # Iterating over each disease\n",
    "        for disease in range(4):\n",
    "            # Appending count of the disease\n",
    "            pred_counts.append([pred1[i], pred2[i], pred3[i]].count(disease))\n",
    "        # Appending argmax of prediction counts\n",
    "        final_pred.append(np.array(pred_counts).argmax())\n",
    "    # Returning final predictions\n",
    "    return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling max_voting_ensemble function\n",
    "max_voting_preds = max_voting_ensemble(EfficientNetB7_preds, baseline_CNN_preds, ResNet50_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parameters\n",
    "plt.rc('xtick', labelsize=8)\n",
    "plt.rc('ytick', labelsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the evaluate_model function\n",
    "max_voting_preds, max_voting_accuracy_score = evaluate_model(model = None,\n",
    "                                                             model_name = 'Max-Voting Ensemble',\n",
    "                                                             model_predictions = max_voting_preds,\n",
    "                                                             error_rows = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficiency Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting current time\n",
    "start = time.time()\n",
    "# Getting EfficientNetB7 preds\n",
    "EfficientNetB7_model_preds = np.argmax(EfficientNetB7_model.predict(test_datagen, verbose=0), axis=-1)\n",
    "# Getting ResNet50 preds\n",
    "ResNet50_model_preds = np.argmax(ResNet50_model.predict(test_datagen, verbose=0), axis=-1)\n",
    "# Getting baseline CNN preds\n",
    "baseline_CNN_model_preds = np.argmax(baseline_CNN_model.predict(test_datagen, verbose=0), axis=-1)\n",
    "# Calling max_voting_ensemble function\n",
    "final_predictions = max_voting_ensemble(EfficientNetB7_model_preds,ResNet50_model_preds,baseline_CNN_model_preds)\n",
    "# Getting current time\n",
    "end = time.time()\n",
    "# Calculating average time to predict a single image\n",
    "print(f'It takes the max-voting ensemble {round((end-start)/1.805,2)} milliseconds to predict a single image.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
